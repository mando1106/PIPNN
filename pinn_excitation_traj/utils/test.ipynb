{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from min_regressor_f_py import min_regressor_f_py as W_min\n",
    "q  = 0.3*np.ones(6)\n",
    "dq = 0.6*np.ones(6)\n",
    "ddq= 0.7*np.ones(6)\n",
    "pi_min = 0.1 + np.arange(48) * 0.05\n",
    "W  = W_min(q, dq, ddq)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(W @ pi_min)        # Display the regressor matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from min_regressor_pytorch import min_regressor_pytorch as W_min\n",
    "# 创建输入张量，开启自动求导\n",
    "# q  = 0.3*torch.ones(6, requires_grad=True)\n",
    "# dq = 0.6*torch.ones(6, requires_grad=True)\n",
    "# ddq= 0.7*torch.ones(6, requires_grad=True)\n",
    "\n",
    "\n",
    "# q = torch.tensor([0.3]*6, requires_grad=True)\n",
    "# dq = torch.tensor([0.6]*6, requires_grad=True)\n",
    "# ddq = torch.tensor([0.7]*6, requires_grad=True)\n",
    "\n",
    "q = torch.full((6,), 0.3, requires_grad=True)  # 直接创建叶子张量\n",
    "dq = torch.full((6,), 0.6, requires_grad=True)  # 直接创建叶子张量\n",
    "ddq = torch.full((6,), 0.7, requires_grad=True)  # 直接创建叶子张量\n",
    "\n",
    "pi_min = 0.1 + torch.arange(48) * 0.05\n",
    "W  = W_min(q, dq, ddq)\n",
    "\n",
    "\n",
    "output = W @ pi_min  # 矩阵乘法，结果是 (6, )\n",
    "\n",
    "print(output)\n",
    "print(W.requires_grad)\n",
    "\n",
    "# 测试是否能求梯度\n",
    "output_sum = output.sum()\n",
    "output_sum.backward()\n",
    "\n",
    "print(q.grad)  # 如果非None，说明梯度支持正常\n",
    "print(dq.grad)\n",
    "print(ddq.grad)   \n",
    "print(\"q.is_leaf:\", q.is_leaf)\n",
    "print(\"dq.is_leaf:\", dq.is_leaf)\n",
    "print(\"ddq.is_leaf:\", ddq.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d95e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from min_regressor_pytorch_matrix import min_regressor_pytorch_matrix as W_min_matrix\n",
    "# 创建输入张量，开启自动求导\n",
    "\n",
    "q = torch.full((10,6), 0.3, requires_grad=True)  # 直接创建叶子张量\n",
    "dq = torch.full((10,6), 0.6, requires_grad=True)  # 直接创建叶子张量\n",
    "ddq = torch.full((10,6), 0.7, requires_grad=True)  # 直接创建叶子张量\n",
    "\n",
    "pi_min = 0.1 + torch.arange(48) * 0.05\n",
    "W  = W_min_matrix(q, dq, ddq)\n",
    "\n",
    "\n",
    "output = W @ pi_min  # 矩阵乘法，结果是 (6, )\n",
    "\n",
    "print(output)\n",
    "print(W.requires_grad)\n",
    "print(W.shape)\n",
    "# 测试是否能求梯度\n",
    "output_sum = output.sum()\n",
    "output_sum.backward()\n",
    "\n",
    "# print(q.grad)  # 如果非None，说明梯度支持正常\n",
    "# print(dq.grad)\n",
    "# print(ddq.grad)   \n",
    "# print(\"q.is_leaf:\", q.is_leaf)\n",
    "# print(\"dq.is_leaf:\", dq.is_leaf)\n",
    "# print(\"ddq.is_leaf:\", ddq.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b90f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_min_matrix forward avg time: 15.2809 ms\n",
      "W_min_matrix_pro forward avg time: 14.2800 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import time\n",
    "from min_regressor_pytorch_matrix import min_regressor_pytorch_matrix as W_min_matrix\n",
    "from min_regressor_pytorch_matrix_pro import min_regressor_pytorch_matrix as W_min_matrix_pro\n",
    "\n",
    "batch =100\n",
    "device = 'cuda' \n",
    "# device = 'cpu'\n",
    "q = torch.full((batch,6), 0.3, device=device, requires_grad=True)\n",
    "dq = torch.full((batch,6), 0.6, device=device, requires_grad=True)\n",
    "ddq = torch.full((batch,6), 0.7, device=device, requires_grad=True)\n",
    "pi_min = (0.1 + torch.arange(48, device=device) * 0.05)\n",
    "\n",
    "\n",
    "# W  = W_min_matrix(q, dq, ddq)\n",
    "# W_p  = W_min_matrix_pro(q, dq, ddq)\n",
    "\n",
    "# output = W @ pi_min  # 矩阵乘法，结果是 (6, )\n",
    "# output = W_p @ pi_min  # 矩阵乘法，结果是 (6, )\n",
    "\n",
    "# W_min_matrix_pro = torch.jit.trace(W_min_matrix_pro, (q, dq, ddq))\n",
    "\n",
    "\n",
    "\n",
    "# 预热一次，避免第一次运行慢的影响\n",
    "_ = W_min_matrix(q, dq, ddq) @ pi_min\n",
    "_ = W_min_matrix_pro(q, dq, ddq) @ pi_min\n",
    "\n",
    "\n",
    "\n",
    "def measure_forward_time(func, q, dq, ddq, pi_min, repeats=100):\n",
    "    # torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    start = time.time()\n",
    "    for _ in range(repeats):\n",
    "        W = func(q, dq, ddq)\n",
    "        out = W @ pi_min\n",
    "    # torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    end = time.time()\n",
    "    avg_time_ms = (end - start) * 1000 / repeats\n",
    "    return avg_time_ms\n",
    "\n",
    "t2 = measure_forward_time(W_min_matrix_pro, q, dq, ddq, pi_min)\n",
    "t1 = measure_forward_time(W_min_matrix, q, dq, ddq, pi_min)\n",
    "\n",
    "\n",
    "print(f\"W_min_matrix forward avg time: {t1:.4f} ms\")\n",
    "print(f\"W_min_matrix_pro forward avg time: {t2:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from min_regressor_pytorch_matrix import min_regressor_pytorch_matrix as W_min_matrix\n",
    "from min_regressor_pytorch_matrix_pro import min_regressor_pytorch_matrix as W_min_matrix_pro\n",
    "\n",
    "def run_test(device: str):\n",
    "    print(f\"\\nRunning on device: {device}\")\n",
    "\n",
    "    batch = 10\n",
    "    # 创建输入张量并放到指定设备，requires_grad=True 保持不变\n",
    "    q = torch.full((batch, 6), 0.3, device=device, requires_grad=True)\n",
    "    dq = torch.full((batch, 6), 0.6, device=device, requires_grad=True)\n",
    "    ddq = torch.full((batch, 6), 0.7, device=device, requires_grad=True)\n",
    "\n",
    "    pi_min = (0.1 + torch.arange(48, device=device) * 0.05).float()\n",
    "\n",
    "    # JIT trace pro 版本（只跟踪一次）\n",
    "    W_min_matrix_pro_jit = torch.jit.trace(W_min_matrix_pro, (q, dq, ddq))\n",
    "\n",
    "    # 预热，防止第一次慢\n",
    "    _ = W_min_matrix(q, dq, ddq) @ pi_min\n",
    "    _ = W_min_matrix_pro_jit(q, dq, ddq) @ pi_min\n",
    "\n",
    "    def measure_forward_time(func, q, dq, ddq, pi_min, repeats=100):\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        for _ in range(repeats):\n",
    "            W = func(q, dq, ddq)\n",
    "            out = W @ pi_min\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        avg_time_ms = (end - start) * 1000 / repeats\n",
    "        return avg_time_ms\n",
    "    t2 = measure_forward_time(W_min_matrix_pro_jit, q, dq, ddq, pi_min)\n",
    "\n",
    "    t1 = measure_forward_time(W_min_matrix, q, dq, ddq, pi_min)\n",
    "\n",
    "    print(f\"W_min_matrix forward avg time: {t1:.4f} ms\")\n",
    "    print(f\"W_min_matrix_pro_jit forward avg time: {t2:.4f} ms\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试CPU\n",
    "    # run_test(\"cpu\")\n",
    "\n",
    "    # # 如果有GPU，测试GPU\n",
    "    if torch.cuda.is_available():\n",
    "        run_test(\"cuda\")\n",
    "    else:\n",
    "        print(\"\\nCUDA is not available on this machine.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
